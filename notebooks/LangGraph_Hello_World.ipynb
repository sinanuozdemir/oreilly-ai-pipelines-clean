{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CRAG - Corrective Retrieval Augmented Generation\n",
    "\n",
    "Inspiration: https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_crag.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-***'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup / Grabbing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://ai-office-hours.beehiiv.com/p/beyond-benchmarks\",\n",
    "    \"https://ai-office-hours.beehiiv.com/p/evaluating-ai-agent-tool-selection\",\n",
    "    \"https://ai-office-hours.beehiiv.com/p/re-ranking-rag\",\n",
    "    \"https://ai-office-hours.beehiiv.com/p/quantizing-llms-llama-3\",\n",
    "    \"https://ai-office-hours.beehiiv.com/p/llm-probing\"\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=512, chunk_overlap=128\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"chroma-rag\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory='./db'\n",
    "    \n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxTG7Kk2xZhm",
    "outputId": "e08810b4-d44d-4fb6-d3e7-6dad5c406ad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probing LLMs for a World ModelAI Office HoursLogin ... https://ai-office-hours.beehiiv.com/p/llm-probing\n",
      "Llama or Mistral, we will grab the embedding of th ... https://ai-office-hours.beehiiv.com/p/llm-probing\n",
      "An investigation into data contamination showed th ... https://ai-office-hours.beehiiv.com/p/beyond-benchmarks\n",
      "using an LLM to write marketing copy or to classif ... https://ai-office-hours.beehiiv.com/p/beyond-benchmarks\n"
     ]
    }
   ],
   "source": [
    "question = \"What is LLM Probing?\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "for doc in docs:\n",
    "    print(doc.page_content[:50], '...', doc.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probing LLMs for a World ModelAI Office HoursLogin ... https://ai-office-hours.beehiiv.com/p/llm-probing\n",
      "Llama or Mistral, we will grab the embedding of th ... https://ai-office-hours.beehiiv.com/p/llm-probing\n",
      "An investigation into data contamination showed th ... https://ai-office-hours.beehiiv.com/p/beyond-benchmarks\n"
     ]
    }
   ],
   "source": [
    "# Only get k=3 documents\n",
    "\n",
    "docs = vectorstore.as_retriever(search_kwargs={'k': 3}).get_relevant_documents(question)\n",
    "for doc in docs:\n",
    "    print(doc.page_content[:50], '...', doc.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhapNmaowfp-",
    "outputId": "98a6405d-d1bb-49bb-93a1-cb99e4c2636f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes' Probing LLMs for a World ModelAI Office HoursLogin ... https://ai-office-hours.beehiiv.com/p/llm-probing\n",
      "binary_score='yes' Llama or Mistral, we will grab the embedding of th ... https://ai-office-hours.beehiiv.com/p/llm-probing\n",
      "binary_score='no' An investigation into data contamination showed th ... https://ai-office-hours.beehiiv.com/p/beyond-benchmarks\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with structured output\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"Give a binary score 'yes' or 'no' to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader  # llm + prompt\n",
    "\n",
    "for doc in docs:\n",
    "    doc_txt = doc.page_content\n",
    "    print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}), doc_txt[:50], '...', doc.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2X8QeJkxye7"
   },
   "source": [
    "## Generate Compoments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yfm8E7gvwu3C",
    "outputId": "8d6e0406-b041-448c-eaad-9cefbb745fc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinanozdemir/Teaching/Pearson/oreilly-ai-pipelines/.venv/lib/python3.11/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.HumanMessagePromptTemplate'>\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "for message in prompt.messages:\n",
    "    print(type(message))\n",
    "    print(message.prompt.template)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUzV8hwgx0G0",
    "outputId": "78fd6604-2e40-4979-992e-c79323472b8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM probing is a technique used to understand how much information is encoded within a language model's parameters by extracting and analyzing embeddings from its hidden layers. It involves applying classifiers or regression models on these embeddings to predict specific attributes, such as birth or death years of individuals mentioned in prompts. The goal is to evaluate the model's internal knowledge representation rather than its performance on a specific task.\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Re-writer / The Corrective Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rX5WDbN6z010",
    "outputId": "b558819c-b304-4107-c5ce-320b4de76d03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is LLM Probing?',\n",
       " 'What does \"LLM probing\" mean in the context of large language models and artificial intelligence research?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A different LLM, just to show we can use multiple LLMs in our calls\n",
    "bigger_llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0.1)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a question re-writer that converts an input question to a better version that is optimized \\n\n",
    "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\n",
    "     \n",
    "Good examples of re-written queries:\n",
    "Original text: \"Make cookie taste better\"\n",
    "Re-Written text: \"Techniques for enchancing flavor of cookie (chocolate chip, sugar, etc)\"\n",
    "\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | bigger_llm | StrOutputParser()\n",
    "question, question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXf2XKOKz1AW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9MlJ26oXzJqw"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "        times_transformed: number of times the question has been re-written\n",
    "        web_search: if we should be doing a web search (not implemented in this notebook)\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    times_transformed: int\n",
    "    web_search: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def set_state(state):\n",
    "    \"\"\"\n",
    "    Sets initial state\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---SET STATE---\")\n",
    "\n",
    "    return {\"times_transformed\": 0}\n",
    "\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    print(state)\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": format_docs(documents), \"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    times_transformed = state[\"times_transformed\"]\n",
    "    times_transformed += 1\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    print('---NEW QUESTION---')\n",
    "    print(better_question)\n",
    "    return {\"question\": better_question, \"times_transformed\": times_transformed}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        print(d.metadata['source'], f'Grade: {grade}')\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "    if len(filtered_docs) == 0:\n",
    "        print(\"---GRADE: DOCUMENTS NOT RELEVANT---\")\n",
    "        web_search = \"Yes\"\n",
    "    return {\"documents\": filtered_docs, \"web_search\": web_search}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dE99Sfa-zOvA"
   },
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    web_search = state[\"web_search\"]\n",
    "    # state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # check times_transformed\n",
    "        if state[\"times_transformed\"] >= 3:\n",
    "            print(\n",
    "                \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION AND WE HAVE TRANSFORMED 3 TIMES, GENERATE---\"\n",
    "            )\n",
    "            return \"should_generate\"\n",
    "\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"should_transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"should_generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "z2wbXWAAzm1k"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"set_state\", set_state)  # set_state\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"set_state\")\n",
    "workflow.add_edge(\"set_state\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"should_transform_query\": \"transform_query\",\n",
    "        \"should_generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJ_wjx_M3Db-",
    "outputId": "6ab8e986-702b-4a26-b4ca-74a0ec593d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---SET STATE---\n",
      "Node 'set_state':\n",
      "{'question': 'What on earth is LLM Probing', 'generation': None, 'documents': None, 'times_transformed': 0, 'web_search': None}\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "Node 'grade_documents':\n",
      "---GENERATE---\n",
      "Node 'generate':\n",
      "LLM probing is a technique to analyze what information is encoded within a large language model's hidden states by extracting embeddings and using them in tasks like linear regression to predict specific attributes (e.g., birth year of a person). It helps evaluate how much factual or structured knowledge the model retains beyond just memorizing text. The goal is to understand the model's internal representations rather than to perform a direct task evaluation.\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "inputs = {\"question\": \"What on earth is LLM Probing\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        print(f\"Node '{key}':\")\n",
    "# Final generation\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---SET STATE---\n",
      "Node 'set_state':\n",
      "{'question': 'make my LLM faster', 'generation': None, 'documents': None, 'times_transformed': 0, 'web_search': None}\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "---GRADE: DOCUMENTS NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "Node 'grade_documents':\n",
      "---TRANSFORM QUERY---\n",
      "---NEW QUESTION---\n",
      "How can I optimize the performance and speed of my large language model (LLM)?\n",
      "Node 'transform_query':\n",
      "{'question': 'How can I optimize the performance and speed of my large language model (LLM)?', 'generation': None, 'documents': [], 'times_transformed': 1, 'web_search': 'Yes'}\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "https://ai-office-hours.beehiiv.com/p/quantizing-llms-llama-3 Grade: yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/llm-probing Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "Node 'grade_documents':\n",
      "---GENERATE---\n",
      "Node 'generate':\n",
      "To optimize the performance and speed of your large language model, consider quantization to reduce memory usage and speed up inference, as demonstrated with Llama-3-8B. However, quantization may slightly reduce accuracy, so fine-tuning the quantized model using techniques like QLORA can help restore or improve performance. Always test the balance between efficiency and accuracy for your specific application.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"make my LLM faster\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        print(f\"Node '{key}':\")\n",
    "# Final generation\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPsnn1CG5QHG",
    "outputId": "8f9299f3-22d4-4101-e7dc-9dbecdd84fea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---SET STATE---\n",
      "Node 'set_state':\n",
      "{'question': 'How to make good inputs to AI?', 'generation': None, 'documents': None, 'times_transformed': 0, 'web_search': None}\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/evaluating-ai-agent-tool-selection Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/quantizing-llms-llama-3 Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "---GRADE: DOCUMENTS NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "Node 'grade_documents':\n",
      "---TRANSFORM QUERY---\n",
      "---NEW QUESTION---\n",
      "Best practices for creating effective prompts and inputs for AI models\n",
      "Node 'transform_query':\n",
      "{'question': 'Best practices for creating effective prompts and inputs for AI models', 'generation': None, 'documents': [], 'times_transformed': 1, 'web_search': 'Yes'}\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/evaluating-ai-agent-tool-selection Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "---GRADE: DOCUMENTS NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "Node 'grade_documents':\n",
      "---TRANSFORM QUERY---\n",
      "---NEW QUESTION---\n",
      "Best strategies and guidelines for designing effective prompts and inputs for AI language models\n",
      "Node 'transform_query':\n",
      "{'question': 'Best strategies and guidelines for designing effective prompts and inputs for AI language models', 'generation': None, 'documents': [], 'times_transformed': 2, 'web_search': 'Yes'}\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/evaluating-ai-agent-tool-selection Grade: no\n",
      "---GRADE: DOCUMENTS NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "Node 'grade_documents':\n",
      "---TRANSFORM QUERY---\n",
      "---NEW QUESTION---\n",
      "Best practices and guidelines for creating effective prompts and inputs for AI language models\n",
      "Node 'transform_query':\n",
      "{'question': 'Best practices and guidelines for creating effective prompts and inputs for AI language models', 'generation': None, 'documents': [], 'times_transformed': 3, 'web_search': 'Yes'}\n",
      "---RETRIEVE---\n",
      "Node 'retrieve':\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/beyond-benchmarks Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/re-ranking-rag Grade: no\n",
      "https://ai-office-hours.beehiiv.com/p/evaluating-ai-agent-tool-selection Grade: no\n",
      "---GRADE: DOCUMENTS NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION AND WE HAVE TRANSFORMED 3 TIMES, GENERATE---\n",
      "Node 'grade_documents':\n",
      "---GENERATE---\n",
      "Node 'generate':\n",
      "Best practices for creating effective prompts include being clear, specific, and concise to guide the AI toward the desired response. Use explicit instructions, provide relevant context, and avoid ambiguity to improve accuracy. Additionally, iterative refinement of prompts based on model outputs can enhance results.\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "inputs = {\"question\": \"How to make good inputs to AI?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        print(f\"Node '{key}':\")\n",
    "# Final generation\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "18SWafVC0Yxn",
    "outputId": "55cc9f34-d2e5-4d6c-c60c-726992960383"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize our graph\n",
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Install grandalf to draw graphs: `pip install grandalf`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Teaching/Pearson/oreilly-ai-pipelines/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph_ascii.py:165\u001b[39m, in \u001b[36m_build_sugiyama_layout\u001b[39m\u001b[34m(vertices, edges)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgrandalf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraphs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Edge, Graph, Vertex  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgrandalf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayouts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SugiyamaLayout  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'grandalf'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# if the above fails try this (requires grandalf)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Teaching/Pearson/oreilly-ai-pipelines/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph.py:478\u001b[39m, in \u001b[36mGraph.draw_ascii\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Draw the graph as an ASCII art string.\"\"\"\u001b[39;00m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_ascii\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_ascii\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_ascii\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Teaching/Pearson/oreilly-ai-pipelines/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph_ascii.py:251\u001b[39m, in \u001b[36mdraw_ascii\u001b[39m\u001b[34m(vertices, edges)\u001b[39m\n\u001b[32m    248\u001b[39m Xs = []\n\u001b[32m    249\u001b[39m Ys = []\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m sug = \u001b[43m_build_sugiyama_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvertices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m vertex \u001b[38;5;129;01min\u001b[39;00m sug.g.sV:\n\u001b[32m    254\u001b[39m     \u001b[38;5;66;03m# NOTE: moving boxes w/2 to the left\u001b[39;00m\n\u001b[32m    255\u001b[39m     Xs.append(vertex.view.xy[\u001b[32m0\u001b[39m] - vertex.view.w / \u001b[32m2.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Teaching/Pearson/oreilly-ai-pipelines/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph_ascii.py:172\u001b[39m, in \u001b[36m_build_sugiyama_layout\u001b[39m\u001b[34m(vertices, edges)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgrandalf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrouting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m    168\u001b[39m         EdgeViewer,\n\u001b[32m    169\u001b[39m         route_with_lines,\n\u001b[32m    170\u001b[39m     )\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    173\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInstall grandalf to draw graphs: `pip install grandalf`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    174\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Just a reminder about naming conventions:\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# +------------X\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# Y\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    186\u001b[39m vertices_ = {\u001b[38;5;28mid\u001b[39m: Vertex(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, data \u001b[38;5;129;01min\u001b[39;00m vertices.items()}\n",
      "\u001b[31mImportError\u001b[39m: Install grandalf to draw graphs: `pip install grandalf`."
     ]
    }
   ],
   "source": [
    "# if the above fails try this (requires grandalf)\n",
    "\n",
    "print(app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (oreilly-ai-pipelines)",
   "language": "python",
   "name": "oreilly-ai-pipelines"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
